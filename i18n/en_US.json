{
    "å¾ˆé—æ†¾æ‚¨è¿™æ²¡æœ‰èƒ½ç”¨çš„æ˜¾å¡æ¥æ”¯æŒæ‚¨è®­ç»ƒ": "Unfortunately, there is no compatible GPU available to support your training.",
    "æ˜¯": "Yes",
    "step1:æ­£åœ¨å¤„ç†æ•°æ®": "Step 1: Processing data",
    "step2a:æ— éœ€æå–éŸ³é«˜": "Step 2a: Skipping pitch extraction",
    "step2b:æ­£åœ¨æå–ç‰¹å¾": "Step 2b: Extracting features",
    "step3a:æ­£åœ¨è®­ç»ƒæ¨¡å‹": "Step 3a: Model training started",
    "è®­ç»ƒç»“æŸ, æ‚¨å¯æŸ¥çœ‹æ§åˆ¶å°è®­ç»ƒæ—¥å¿—æˆ–å®éªŒæ–‡ä»¶å¤¹ä¸‹çš„train.log": "Training complete. You can check the training logs in the console or the 'train.log' file under the experiment folder.",
    "å…¨æµç¨‹ç»“æŸï¼": "All processes have been completed!",
    "æœ¬è½¯ä»¶ä»¥MITåè®®å¼€æº, ä½œè€…ä¸å¯¹è½¯ä»¶å…·å¤‡ä»»ä½•æ§åˆ¶åŠ›, ä½¿ç”¨è½¯ä»¶è€…ã€ä¼ æ’­è½¯ä»¶å¯¼å‡ºçš„å£°éŸ³è€…è‡ªè´Ÿå…¨è´£. <br>å¦‚ä¸è®¤å¯è¯¥æ¡æ¬¾, åˆ™ä¸èƒ½ä½¿ç”¨æˆ–å¼•ç”¨è½¯ä»¶åŒ…å†…ä»»ä½•ä»£ç å’Œæ–‡ä»¶. è¯¦è§æ ¹ç›®å½•<b>ä½¿ç”¨éœ€éµå®ˆçš„åè®®-LICENSE.txt</b>.": "This software is open source under the MIT license. The author does not have any control over the software. Users who use the software and distribute the sounds exported by the software are solely responsible. <br>If you do not agree with this clause, you cannot use or reference any codes and files within the software package. See the root directory <b>Agreement-LICENSE.txt</b> for details.",
    "æ¨¡å‹æ¨ç†": "Model Inference",
    "æ¨ç†éŸ³è‰²": "Inferencing voice:",
    "åˆ·æ–°éŸ³è‰²åˆ—è¡¨å’Œç´¢å¼•è·¯å¾„": "Refresh voice list and index path",
    "å¸è½½éŸ³è‰²çœæ˜¾å­˜": "Unload voice to save GPU memory:",
    "è¯·é€‰æ‹©è¯´è¯äººid": "Select Speaker/Singer ID:",
    "ç”·è½¬å¥³æ¨è+12key, å¥³è½¬ç”·æ¨è-12key, å¦‚æœéŸ³åŸŸçˆ†ç‚¸å¯¼è‡´éŸ³è‰²å¤±çœŸä¹Ÿå¯ä»¥è‡ªå·±è°ƒæ•´åˆ°åˆé€‚éŸ³åŸŸ. ": "Recommended +12 key for male to female conversion, and -12 key for female to male conversion. If the sound range goes too far and the voice is distorted, you can also adjust it to the appropriate range by yourself.",
    "å˜è°ƒ(æ•´æ•°, åŠéŸ³æ•°é‡, å‡å…«åº¦12é™å…«åº¦-12)": "Transpose (integer, number of semitones, raise by an octave: 12, lower by an octave: -12):",
    "è¾“å…¥å¾…å¤„ç†éŸ³é¢‘æ–‡ä»¶è·¯å¾„(é»˜è®¤æ˜¯æ­£ç¡®æ ¼å¼ç¤ºä¾‹)": "Enter the path of the audio file to be processed (default is the correct format example):",
    "é€‰æ‹©éŸ³é«˜æå–ç®—æ³•,è¾“å…¥æ­Œå£°å¯ç”¨pmæé€Ÿ,harvestä½éŸ³å¥½ä½†å·¨æ…¢æ— æ¯”,crepeæ•ˆæœå¥½ä½†åƒGPU": "Select the pitch extraction algorithm ('pm': faster extraction but lower-quality speech; 'harvest': better bass but extremely slow; 'crepe': better quality but GPU intensive):",
    "crepe_hop_length": "Mangio-Crepe Hop Length (Only applies to mangio-crepe): Hop length refers to the time it takes for the speaker to jump to a dramatic pitch. Lower hop lengths take more time to infer but are more pitch accurate.",
    "ç‰¹å¾æ£€ç´¢åº“æ–‡ä»¶è·¯å¾„": "Feature search database file path",
    ">=3åˆ™ä½¿ç”¨å¯¹harvestéŸ³é«˜è¯†åˆ«çš„ç»“æœä½¿ç”¨ä¸­å€¼æ»¤æ³¢ï¼Œæ•°å€¼ä¸ºæ»¤æ³¢åŠå¾„ï¼Œä½¿ç”¨å¯ä»¥å‰Šå¼±å“‘éŸ³": "If >=3: apply median filtering to the harvested pitch results. The value represents the filter radius and can reduce breathiness.",
    "ç‰¹å¾æ£€ç´¢åº“æ–‡ä»¶è·¯å¾„,ä¸ºç©ºåˆ™ä½¿ç”¨ä¸‹æ‹‰çš„é€‰æ‹©ç»“æœ": "Path to the feature index file. Leave blank to use the selected result from the dropdown:",
    "è‡ªåŠ¨æ£€æµ‹indexè·¯å¾„,ä¸‹æ‹‰å¼é€‰æ‹©(dropdown)": "Auto-detect index path and select from the dropdown:",
    "ç‰¹å¾æ–‡ä»¶è·¯å¾„": "Path to feature file:",
    "æ£€ç´¢ç‰¹å¾å æ¯”": "Search feature ratio:",
    "åå¤„ç†é‡é‡‡æ ·è‡³æœ€ç»ˆé‡‡æ ·ç‡ï¼Œ0ä¸ºä¸è¿›è¡Œé‡é‡‡æ ·": "Resample the output audio in post-processing to the final sample rate. Set to 0 for no resampling:",
    "è¾“å…¥æºéŸ³é‡åŒ…ç»œæ›¿æ¢è¾“å‡ºéŸ³é‡åŒ…ç»œèåˆæ¯”ä¾‹ï¼Œè¶Šé è¿‘1è¶Šä½¿ç”¨è¾“å‡ºåŒ…ç»œ": "Use the volume envelope of the input to replace or mix with the volume envelope of the output. The closer the ratio is to 1, the more the output envelope is used:",
    "ä¿æŠ¤æ¸…è¾…éŸ³å’Œå‘¼å¸å£°ï¼Œé˜²æ­¢ç”µéŸ³æ’•è£‚ç­‰artifactï¼Œæ‹‰æ»¡0.5ä¸å¼€å¯ï¼Œè°ƒä½åŠ å¤§ä¿æŠ¤åŠ›åº¦ä½†å¯èƒ½é™ä½ç´¢å¼•æ•ˆæœ": "Protect voiceless consonants and breath sounds to prevent artifacts such as tearing in electronic music. Set to 0.5 to disable. Decrease the value to increase protection, but it may reduce indexing accuracy:",
    "F0æ›²çº¿æ–‡ä»¶, å¯é€‰, ä¸€è¡Œä¸€ä¸ªéŸ³é«˜, ä»£æ›¿é»˜è®¤F0åŠå‡é™è°ƒ": "F0 curve file (optional). One pitch per line. Replaces the default F0 and pitch modulation:",
    "è½¬æ¢": "Convert",
    "è¾“å‡ºä¿¡æ¯": "Output information",
    "è¾“å‡ºéŸ³é¢‘(å³ä¸‹è§’ä¸‰ä¸ªç‚¹,ç‚¹äº†å¯ä»¥ä¸‹è½½)": "Export audio (click on the three dots in the lower right corner to download)",
    "æ‰¹é‡è½¬æ¢, è¾“å…¥å¾…è½¬æ¢éŸ³é¢‘æ–‡ä»¶å¤¹, æˆ–ä¸Šä¼ å¤šä¸ªéŸ³é¢‘æ–‡ä»¶, åœ¨æŒ‡å®šæ–‡ä»¶å¤¹(é»˜è®¤opt)ä¸‹è¾“å‡ºè½¬æ¢çš„éŸ³é¢‘. ": "Batch conversion. Enter the folder containing the audio files to be converted or upload multiple audio files. The converted audio will be output in the specified folder (default: 'opt').",
    "æŒ‡å®šè¾“å‡ºæ–‡ä»¶å¤¹": "Specify output folder:",
    "è¾“å…¥å¾…å¤„ç†éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„(å»æ–‡ä»¶ç®¡ç†å™¨åœ°å€æ æ‹·å°±è¡Œäº†)": "Enter the path of the audio folder to be processed (copy it from the address bar of the file manager):",
    "ä¹Ÿå¯æ‰¹é‡è¾“å…¥éŸ³é¢‘æ–‡ä»¶, äºŒé€‰ä¸€, ä¼˜å…ˆè¯»æ–‡ä»¶å¤¹": "You can also input audio files in batches. Choose one of the two options. Priority is given to reading from the folder.",
    "å¯¼å‡ºæ–‡ä»¶æ ¼å¼": "Export file format",
    "ä¼´å¥äººå£°åˆ†ç¦»&å»æ··å“&å»å›å£°": "Vocals/Accompaniment Separation & Reverberation Removal",
    "è¾“å…¥å¾…å¤„ç†éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„": "Enter the path of the audio folder to be processed:",
    "æ¨¡å‹": "Model",
    "æŒ‡å®šè¾“å‡ºä¸»äººå£°æ–‡ä»¶å¤¹": "Specify the output folder for vocals:",
    "æŒ‡å®šè¾“å‡ºéä¸»äººå£°æ–‡ä»¶å¤¹": "Specify the output folder for accompaniment:",
    "è®­ç»ƒ": "Train",
    "step1: å¡«å†™å®éªŒé…ç½®. å®éªŒæ•°æ®æ”¾åœ¨logsä¸‹, æ¯ä¸ªå®éªŒä¸€ä¸ªæ–‡ä»¶å¤¹, éœ€æ‰‹å·¥è¾“å…¥å®éªŒåè·¯å¾„, å†…å«å®éªŒé…ç½®, æ—¥å¿—, è®­ç»ƒå¾—åˆ°çš„æ¨¡å‹æ–‡ä»¶. ": "Step 1: Fill in the experimental configuration. Experimental data is stored in the 'logs' folder, with each experiment having a separate folder. Manually enter the experiment name path, which contains the experimental configuration, logs, and trained model files.",
    "è¾“å…¥å®éªŒå": "Enter the experiment name:",
    "ç›®æ ‡é‡‡æ ·ç‡": "Target sample rate:",
    "æ¨¡å‹æ˜¯å¦å¸¦éŸ³é«˜æŒ‡å¯¼(å”±æ­Œä¸€å®šè¦, è¯­éŸ³å¯ä»¥ä¸è¦)": "Whether the model has pitch guidance (required for singing, optional for speech):",
    "ç‰ˆæœ¬": "Version",
    "æå–éŸ³é«˜å’Œå¤„ç†æ•°æ®ä½¿ç”¨çš„CPUè¿›ç¨‹æ•°": "Number of CPU processes used for pitch extraction and data processing:",
    "step2a: è‡ªåŠ¨éå†è®­ç»ƒæ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰å¯è§£ç æˆéŸ³é¢‘çš„æ–‡ä»¶å¹¶è¿›è¡Œåˆ‡ç‰‡å½’ä¸€åŒ–, åœ¨å®éªŒç›®å½•ä¸‹ç”Ÿæˆ2ä¸ªwavæ–‡ä»¶å¤¹; æš‚æ—¶åªæ”¯æŒå•äººè®­ç»ƒ. ": "Step 2a: Automatically traverse all files in the training folder that can be decoded into audio and perform slice normalization. Generates 2 wav folders in the experiment directory. Currently, only single-singer/speaker training is supported.",
    "è¾“å…¥è®­ç»ƒæ–‡ä»¶å¤¹è·¯å¾„": "Enter the path of the training folder:",
    "è¯·æŒ‡å®šè¯´è¯äººid": "Please specify the speaker/singer ID:",
    "å¤„ç†æ•°æ®": "Process data",
    "step2b: ä½¿ç”¨CPUæå–éŸ³é«˜(å¦‚æœæ¨¡å‹å¸¦éŸ³é«˜), ä½¿ç”¨GPUæå–ç‰¹å¾(é€‰æ‹©å¡å·)": "Step 2b: Use CPU to extract pitch (if the model has pitch), use GPU to extract features (select GPU index):",
    "ä»¥-åˆ†éš”è¾“å…¥ä½¿ç”¨çš„å¡å·, ä¾‹å¦‚   0-1-2   ä½¿ç”¨å¡0å’Œå¡1å’Œå¡2": "Enter the GPU index(es) separated by '-', e.g., 0-1-2 to use GPU 0, 1, and 2:",
    "æ˜¾å¡ä¿¡æ¯": "GPU Information",
    "é€‰æ‹©éŸ³é«˜æå–ç®—æ³•:è¾“å…¥æ­Œå£°å¯ç”¨pmæé€Ÿ,é«˜è´¨é‡è¯­éŸ³ä½†CPUå·®å¯ç”¨dioæé€Ÿ,harvestè´¨é‡æ›´å¥½ä½†æ…¢": "Select the pitch extraction algorithm ('pm': faster extraction but lower-quality speech; 'dio': improved speech but slower extraction; 'harvest': better quality but slower extraction):",
    "ç‰¹å¾æå–": "Feature extraction",
    "step3: å¡«å†™è®­ç»ƒè®¾ç½®, å¼€å§‹è®­ç»ƒæ¨¡å‹å’Œç´¢å¼•": "Step 3: Fill in the training settings and start training the model and index",
    "ä¿å­˜é¢‘ç‡save_every_epoch": "Save frequency (save_every_epoch):",
    "æ€»è®­ç»ƒè½®æ•°total_epoch": "Total training epochs (total_epoch):",
    "æ¯å¼ æ˜¾å¡çš„batch_size": "Batch size per GPU:",
    "æ˜¯å¦ä»…ä¿å­˜æœ€æ–°çš„ckptæ–‡ä»¶ä»¥èŠ‚çœç¡¬ç›˜ç©ºé—´": "Save only the latest '.ckpt' file to save disk space:",
    "å¦": "No",
    "æ˜¯å¦ç¼“å­˜æ‰€æœ‰è®­ç»ƒé›†è‡³æ˜¾å­˜. 10minä»¥ä¸‹å°æ•°æ®å¯ç¼“å­˜ä»¥åŠ é€Ÿè®­ç»ƒ, å¤§æ•°æ®ç¼“å­˜ä¼šç‚¸æ˜¾å­˜ä¹ŸåŠ ä¸äº†å¤šå°‘é€Ÿ": "Cache all training sets to GPU memory. Caching small datasets (less than 10 minutes) can speed up training, but caching large datasets will consume a lot of GPU memory and may not provide much speed improvement:",
    "æ˜¯å¦åœ¨æ¯æ¬¡ä¿å­˜æ—¶é—´ç‚¹å°†æœ€ç»ˆå°æ¨¡å‹ä¿å­˜è‡³weightsæ–‡ä»¶å¤¹": "Save a small final model to the 'weights' folder at each save point:",
    "åŠ è½½é¢„è®­ç»ƒåº•æ¨¡Gè·¯å¾„": "Load pre-trained base model G path:",
    "åŠ è½½é¢„è®­ç»ƒåº•æ¨¡Dè·¯å¾„": "Load pre-trained base model D path:",
    "è®­ç»ƒæ¨¡å‹": "Train model",
    "è®­ç»ƒç‰¹å¾ç´¢å¼•": "Train feature index",
    "ä¸€é”®è®­ç»ƒ": "One-click training",
    "ckptå¤„ç†": "ckpt Processing",
    "æ¨¡å‹èåˆ, å¯ç”¨äºæµ‹è¯•éŸ³è‰²èåˆ": "Model fusion, can be used to test timbre fusion",
    "Aæ¨¡å‹è·¯å¾„": "Path to Model A:",
    "Bæ¨¡å‹è·¯å¾„": "Path to Model B:",
    "Aæ¨¡å‹æƒé‡": "Weight (w) for Model A:",
    "æ¨¡å‹æ˜¯å¦å¸¦éŸ³é«˜æŒ‡å¯¼": "Whether the model has pitch guidance:",
    "è¦ç½®å…¥çš„æ¨¡å‹ä¿¡æ¯": "Model information to be placed:",
    "ä¿å­˜çš„æ¨¡å‹åä¸å¸¦åç¼€": "Saved model name (without extension):",
    "æ¨¡å‹ç‰ˆæœ¬å‹å·": "Model architecture version:",
    "èåˆ": "Fusion",
    "ä¿®æ”¹æ¨¡å‹ä¿¡æ¯(ä»…æ”¯æŒweightsæ–‡ä»¶å¤¹ä¸‹æå–çš„å°æ¨¡å‹æ–‡ä»¶)": "Modify model information (only supported for small model files extracted from the 'weights' folder)",
    "æ¨¡å‹è·¯å¾„": "Path to Model:",
    "è¦æ”¹çš„æ¨¡å‹ä¿¡æ¯": "Model information to be modified:",
    "ä¿å­˜çš„æ–‡ä»¶å, é»˜è®¤ç©ºä¸ºå’Œæºæ–‡ä»¶åŒå": "Save file name (default: same as the source file):",
    "ä¿®æ”¹": "Modify",
    "æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯(ä»…æ”¯æŒweightsæ–‡ä»¶å¤¹ä¸‹æå–çš„å°æ¨¡å‹æ–‡ä»¶)": "View model information (only supported for small model files extracted from the 'weights' folder)",
    "æŸ¥çœ‹": "View",
    "æ¨¡å‹æå–(è¾“å…¥logsæ–‡ä»¶å¤¹ä¸‹å¤§æ–‡ä»¶æ¨¡å‹è·¯å¾„),é€‚ç”¨äºè®­ä¸€åŠä¸æƒ³è®­äº†æ¨¡å‹æ²¡æœ‰è‡ªåŠ¨æå–ä¿å­˜å°æ–‡ä»¶æ¨¡å‹,æˆ–è€…æƒ³æµ‹è¯•ä¸­é—´æ¨¡å‹çš„æƒ…å†µ": "Model extraction (enter the path of the large file model under the 'logs' folder). This is useful if you want to stop training halfway and manually extract and save a small model file, or if you want to test an intermediate model:",
    "ä¿å­˜å": "Save name:",
    "æ¨¡å‹æ˜¯å¦å¸¦éŸ³é«˜æŒ‡å¯¼,1æ˜¯0å¦": "Whether the model has pitch guidance (1: yes, 0: no):",
    "æå–": "Extract",
    "Onnxå¯¼å‡º": "Export Onnx",
    "RVCæ¨¡å‹è·¯å¾„": "RVC Model Path:",
    "Onnxè¾“å‡ºè·¯å¾„": "Onnx Export Path:",
    "MoeVSæ¨¡å‹": "MoeVS Model",
    "å¯¼å‡ºOnnxæ¨¡å‹": "Export Onnx Model",
    "å¸¸è§é—®é¢˜è§£ç­”": "FAQ (Frequently Asked Questions)",
    "æ‹›å‹ŸéŸ³é«˜æ›²çº¿å‰ç«¯ç¼–è¾‘å™¨": "Recruiting front-end editors for pitch curves",
    "åŠ å¼€å‘ç¾¤è”ç³»æˆ‘xxxxx": "Join the development group and contact me at xxxxx",
    "ç‚¹å‡»æŸ¥çœ‹äº¤æµã€é—®é¢˜åé¦ˆç¾¤å·": "Click to view the communication and problem feedback group number",
    "xxxxx": "xxxxx",
    "åŠ è½½æ¨¡å‹": "Load model",
    "Hubertæ¨¡å‹": "Hubert Model",
    "é€‰æ‹©.pthæ–‡ä»¶": "Select the .pth file",
    "é€‰æ‹©.indexæ–‡ä»¶": "Select the .index file",
    "é€‰æ‹©.npyæ–‡ä»¶": "Select the .npy file",
    "è¾“å…¥è®¾å¤‡": "Input device",
    "è¾“å‡ºè®¾å¤‡": "Output device",
    "éŸ³é¢‘è®¾å¤‡(è¯·ä½¿ç”¨åŒç§ç±»é©±åŠ¨)": "Audio device (please use the same type of driver)",
    "å“åº”é˜ˆå€¼": "Response threshold",
    "éŸ³è°ƒè®¾ç½®": "Pitch settings",
    "Index Rate": "Index Rate",
    "å¸¸è§„è®¾ç½®": "General settings",
    "é‡‡æ ·é•¿åº¦": "Sample length",
    "æ·¡å…¥æ·¡å‡ºé•¿åº¦": "Fade length",
    "é¢å¤–æ¨ç†æ—¶é•¿": "Extra inference time",
    "è¾“å…¥é™å™ª": "Input noise reduction",
    "è¾“å‡ºé™å™ª": "Output noise reduction",
    "æ€§èƒ½è®¾ç½®": "Performance settings",
    "å¼€å§‹éŸ³é¢‘è½¬æ¢": "Start audio conversion",
    "åœæ­¢éŸ³é¢‘è½¬æ¢": "Stop audio conversion",
    "æ¨ç†æ—¶é—´(ms):": "Inference time (ms):",
    "äººå£°ä¼´å¥åˆ†ç¦»æ‰¹é‡å¤„ç†ï¼Œ ä½¿ç”¨UVR5æ¨¡å‹ã€‚ <br>åˆæ ¼çš„æ–‡ä»¶å¤¹è·¯å¾„æ ¼å¼ä¸¾ä¾‹ï¼š E:\\codes\\py39\\vits_vc_gpu\\ç™½é¹­éœœåæµ‹è¯•æ ·ä¾‹(å»æ–‡ä»¶ç®¡ç†å™¨åœ°å€æ æ‹·å°±è¡Œäº†)ã€‚ <br>æ¨¡å‹åˆ†ä¸ºä¸‰ç±»ï¼š <br>1ã€ä¿ç•™äººå£°ï¼šä¸å¸¦å’Œå£°çš„éŸ³é¢‘é€‰è¿™ä¸ªï¼Œå¯¹ä¸»äººå£°ä¿ç•™æ¯”HP5æ›´å¥½ã€‚å†…ç½®HP2å’ŒHP3ä¸¤ä¸ªæ¨¡å‹ï¼ŒHP3å¯èƒ½è½»å¾®æ¼ä¼´å¥ä½†å¯¹ä¸»äººå£°ä¿ç•™æ¯”HP2ç¨å¾®å¥½ä¸€ä¸ç‚¹ï¼› <br>2ã€ä»…ä¿ç•™ä¸»äººå£°ï¼šå¸¦å’Œå£°çš„éŸ³é¢‘é€‰è¿™ä¸ªï¼Œå¯¹ä¸»äººå£°å¯èƒ½æœ‰å‰Šå¼±ã€‚å†…ç½®HP5ä¸€ä¸ªæ¨¡å‹ï¼› <br> 3ã€å»æ··å“ã€å»å»¶è¿Ÿæ¨¡å‹ï¼ˆby FoxJoyï¼‰ï¼š<br>â€ƒâ€ƒ(1)MDX-Net(onnx_dereverb):å¯¹äºåŒé€šé“æ··å“æ˜¯æœ€å¥½çš„é€‰æ‹©ï¼Œä¸èƒ½å»é™¤å•é€šé“æ··å“ï¼›<br>&emsp;(234)DeEcho:å»é™¤å»¶è¿Ÿæ•ˆæœã€‚Aggressiveæ¯”Normalå»é™¤å¾—æ›´å½»åº•ï¼ŒDeReverbé¢å¤–å»é™¤æ··å“ï¼Œå¯å»é™¤å•å£°é“æ··å“ï¼Œä½†æ˜¯å¯¹é«˜é¢‘é‡çš„æ¿å¼æ··å“å»ä¸å¹²å‡€ã€‚<br>å»æ··å“/å»å»¶è¿Ÿï¼Œé™„ï¼š<br>1ã€DeEcho-DeReverbæ¨¡å‹çš„è€—æ—¶æ˜¯å¦å¤–2ä¸ªDeEchoæ¨¡å‹çš„æ¥è¿‘2å€ï¼›<br>2ã€MDX-Net-Dereverbæ¨¡å‹æŒºæ…¢çš„ï¼›<br>3ã€ä¸ªäººæ¨èçš„æœ€å¹²å‡€çš„é…ç½®æ˜¯å…ˆMDX-Netå†DeEcho-Aggressiveã€‚":"Batch processing for vocal accompaniment separation using the UVR5 model.<br>Example of a valid folder path format: D:\\path\\to\\input\\folder (copy it from the file manager address bar).<br>The model is divided into three categories:<br>1. Preserve vocals: Choose this option for audio without harmonies. It preserves vocals better than HP5. It includes two built-in models: HP2 and HP3. HP3 may slightly leak accompaniment but preserves vocals slightly better than HP2.<br>2. Preserve main vocals only: Choose this option for audio with harmonies. It may weaken the main vocals. It includes one built-in model: HP5.<br>3. De-reverb and de-delay models (by FoxJoy):<br>â€ƒâ€ƒ(1) MDX-Net: The best choice for stereo reverb removal but cannot remove mono reverb;<br>&emsp;(234) DeEcho: Removes delay effects. Aggressive mode removes more thoroughly than Normal mode. DeReverb additionally removes reverb and can remove mono reverb, but not very effectively for heavily reverberated high-frequency content.<br>De-reverb/de-delay notes:<br>1. The processing time for the DeEcho-DeReverb model is approximately twice as long as the other two DeEcho models.<br>2. The MDX-Net-Dereverb model is quite slow.<br>3. The recommended cleanest configuration is to apply MDX-Net first and then DeEcho-Aggressive.",
    "<h1> The Mangio-RVC-Fork ğŸ’» </h1>": "<h1> The Mangio-RVC-Fork ğŸ’» </h1>",
    "mi-test": "mi-test",
    "You need to upload an audio": "You need to upload an audio",
    "Using index:%s.": "Using index:%s.",
    "Index not used.": "Index not used.",
    "Success.\n %s\nTime:\n npy:%ss, f0:%ss, infer:%ss": "Success.\n %s\nTime:\n npy:%ss, f0:%ss, infer:%ss",
    "not exist, will not use pretrained model": "Not exist, will not use pretrained model",
    "è¯·å…ˆè¿›è¡Œç‰¹å¾æå–!": "Run resource extraction first!",
    "Trying doing kmeans %s shape to 10k centers.": "Trying doing kmeans %s shape to 10k centers.",
    "æˆåŠŸæ„å»ºç´¢å¼•ï¼Œadded_IVF%s_Flat_nprobe_%s_%s_%s.index": "Index created successfully, adicionado_IVF%s_Flat_nprobe_%s_%s_%s.index",
    "step2a:æ­£åœ¨æå–éŸ³é«˜": "step2a: extracting tone",
    "training index": "training index",
    "adding index": "adding index",
    "æˆåŠŸæ„å»ºç´¢å¼•, added_IVF%s_Flat_nprobe_%s_%s_%s.index": "Index created successfully, added_IVF%s_Flat_nprobe_%s_%s_%s.index",
    "E:\\codes\\py39\\test-20230416b\\todo-songs": "E:\\all-my-audios",
    "E:\\è¯­éŸ³éŸ³é¢‘+æ ‡æ³¨\\ç±³æ´¥ç„å¸ˆ\\src": "E:\\dataset",
    "äººå£°æå–æ¿€è¿›ç¨‹åº¦": "Aggressiveness of vocal extraction",
    "[EXPERIMENTAL] Formant shift inference audio": "[EXPERIMENTAL] Formant shift inference audio",
    "Used for male to female and vice-versa conversions": "Used for male to female and vice-versa conversions",
    "browse presets for formanting": "browse presets for formanting",
    "Quefrency for formant shifting": "Quefrency for formant shifting",
    "Timbre for formant shifting": "Timbre for formant shifting",
    "Stop Training": "Stop Training",
    "Whether the model has pitch guidance.": "Whether the model has pitch guidance.",
    "Whether to save only the latest .ckpt file to save hard disk space": "Whether to save only the latest .ckpt file to save hard disk space",
    "Cache all training sets to GPU memory. Caching small datasets (less than 10 minutes) can speed up training, but caching large datasets will consume a lot of GPU memory and may not provide much speed improvement": "Cache all training sets to GPU memory. Caching small datasets (less than 10 minutes) can speed up training, but caching large datasets will consume a lot of GPU memory and may not provide much speed improvement",
    "Save a small final model to the 'weights' folder at each save point": "Save a small final model to the 'weights' folder at each save point",
    "Path to your model A.": "Path to your model A.",
    "Path to your model B.": "Path to your model B.",
    "Path to your Model.": "Path to your Model.",
    "Model information to be changed.": "Model information to be changed.",
    "Name for saving.": "Name for saving.",
    "Either leave empty or put in the Name of the Model to be saved.": "Either leave empty or put in the Name of the Model to be saved.",
    "Model path here.":  "Model path here.",
    "Your filename here.": "Your filename here.",
    "Model info here.": "Model info here.",
    "RVC model path.": "RVC model path.",
    "Onnx model output path.": "Onnx model output path.",
    "Default value is 1.0": "Default value is 1.0",
    "Apply": "Apply",


    
    "___comment___": "EasierGUI",
    



    "<h1> Easy GUI v2 (rejekts) - adapted to Mangio-RVC-Fork ğŸ’» </h1>": "<h1> Easy GUI v2 (rejekts) - adapted to Mangio-RVC-Fork ğŸ’» </h1>",
    "1.Choose your Model.": "1.Choose your Model.",
    "Refresh": "Refresh",
    "Optional: You can change the pitch here or leave it at 0.": "Optional: You can change the pitch here or leave it at 0.",
    "Convert": "Convert",
    "Drop your audio here & hit the Reload button.": "Drop your audio here & hit the Reload button.",
    "OR Record audio.": "OR Record audio.",
    "2.Choose your audio.": "2.Choose your audio.",
    "Text To Speech": "Text To Speech",
    "Chinese & Japanese do not work with ElevenLabs currently.": "Chinese & Japanese do not work with ElevenLabs currently.",
    "en": "en",
    "Enter your API Key for ElevenLabs, or leave empty to use GoogleTTS": "Enter your API Key for ElevenLabs, or leave empty to use GoogleTTS",
    "Voice:": "Voice:",
    "Input your Text": "Input your Text",
    "This is a test.": "This is a test.",
    "Speak": "Speak",
    "Wav2Lip": "Wav2Lip",
    "Resolution:": "Resolution:",
    "Upload A Character": "Upload A Character",
    "Half": "Half",
    "Full": "Full",
    "OR Choose one:": "OR Choose one:",
    "Status:": "Status:",
    "Animate": "Animate",
    "Index Settings": "Index Settings",
    "Output Audio (Click on the Three Dots in the Right Corner to Download)": "Output Audio (Click on the Three Dots in the Right Corner to Download)",
    "Advanced Settings": "Advanced Settings",
    "Optional: Change the Pitch Extraction Algorithm.": "Optional: Change the Pitch Extraction Algorithm.",
    "Mangio-Crepe Hop Length. Higher numbers will reduce the chance of extreme pitch changes but lower numbers will increase accuracy.": "Mangio-Crepe Hop Length. Higher numbers will reduce the chance of extreme pitch changes but lower numbers will increase accuracy.",
    "Batch Conversion": "Batch Conversion",
    "Download Model": "Download Model",
    "Enter the URL to the Model:": "Enter the URL to the Model:",
    "Name your model:": "Name your model:",
    "Download": "Download",
    "Train": "Train",
    "Voice Name:": "Voice Name:",
    "My-Voice": "My-Voice",
    "RVC version": "RVC version",
    "# of CPUs for data processing (Leave as it is)": "# of CPUs for data processing (Leave as it is)",
    "Path to your dataset (audios, not zip):": "Path to your dataset (audios, not zip):",
    "OR Drop your audios here. They will be uploaded in your dataset path above.": "OR Drop your audios here. They will be uploaded in your dataset path above.",
    "3. Path to your added.index file (if it didn't automatically find it.)": "3. Path to your added.index file (if it didn't automatically find it.)",
	"1. Process The Dataset": "1.Process The Dataset",
    "GPU Settings": "GPU Settings",
    "crepe_hop_length": "Mangio-Crepe Hop Length (Only applies to mangio-crepe): Hop length refers to the time it takes for the speaker to jump to a dramatic pitch. Lower hop lengths take more time to infer but are more pitch accurate.",
    "2. Pitch Extraction": "2.Pitch Extraction",
    "Total # of training epochs (IF you choose a value too high, your model will sound horribly overtrained.):": "Total # of training epochs (IF you choose a value too high, your model will sound horribly overtrained.):",
    "3. Train Model": "3.Train Model",
    "4.Train Index": "4.Train Index",
    "Training Preferences (You can leave these as they are)": "Training Preferences (You can leave these as they are)",
    "Backup every # of epochs:": "Backup every # of epochs:",
    "5.Download Model": "5.Download Model",
    "Your Model and Index file can be downloaded here:": "Your Model and Index file can be downloaded here:",
    "Base Model Locations:": "Base Model Locations",
    "Saved Preset %s into inference-presets.json!": "Saved Preset %s into inference-presets.json!",
    "Changed Preset to %s!": "Changed Preset to %s!",
    "Searching for ": "Searching for ",
    "Found a preset": "Found a preset",
	"Status (wait until it says 'end preprocess'):": "Status (wait until it says 'end preprocess'):",
	"Status(Check the Colab Notebook's cell output):": "Status(Check the Colab Notebook's cell output):",
	"Batch Size (LEAVE IT unless you know what you're doing!):": "Batch Size (LEAVE IT unless you know what you're doing!):",
	"Original RVC:https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI<br>Mangio's RVC Fork:https://github.com/Mangio621/Mangio-RVC-Fork<br>â¤ï¸ If you like the EasyGUI, help me keep it.â¤ï¸ https://paypal.me/lesantillan": "Original RVC:https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI<br>Mangio's RVC Fork:https://github.com/Mangio621/Mangio-RVC-Fork<br>â¤ï¸ If you like the EasyGUI, help me keep it.â¤ï¸ https://paypal.me/lesantillan",
    "Save only the latest '.ckpt' file to save disk space.": "Se deve salvar apenas o arquivo .ckpt mais recente para economizar espaÃ§o no disco rÃ­gido",
    "Cache all training sets to GPU memory. Caching small datasets (less than 10 minutes) can speed up training, but caching large datasets will consume a lot of GPU memory and may not provide much speed improvement.": "Armazene em cache todos os conjuntos de treinamento na memÃ³ria da GPU. O armazenamento em cache de pequenos conjuntos de dados (menos de 10 minutos) pode acelerar o treinamento, mas o armazenamento em cache de grandes conjuntos de dados consome muita memÃ³ria da GPU e pode nÃ£o fornecer muita melhoria de velocidade.",
    "Save a small final model to the 'weights' folder at each save point.": "Salve um pequeno modelo final na pasta 'weights' em cada ponto de salvamento.",
    "Time Calculator": "Time Calculator",
    "Number of initial epochs:": "Number of initial epochs:",
    "Number of final epochs:": "Number of final epochs:",
    "Average time per epoch (seconds):": "Average time per epoch (seconds):",
    "Calculate": "Calculate",
    "Result": "Result",
    "{horas}:{minutos}\n\nIt will take {horas} hr(s): {minutos} minute(s): {segundos} and second(s) approximately": "{horas}:{minutos}\n\nIt will take {horas} hr(s): {minutos} minute(s): {segundos} and second(s) approximately",
    "Minutes to Seconds": "Minutes to Seconds",
    "Minutes": "Minutes",
    "{mintosec} seconds.": "{mintosec} seconds."
}